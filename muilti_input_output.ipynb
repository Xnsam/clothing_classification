{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "muilti_input_output.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "hnZOHOo7bCG9",
        "Faw21gWojnmF",
        "fQZezb0t7MfR",
        "YxEXOlai-ODg",
        "wlI4WV626CkK"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnZOHOo7bCG9",
        "colab_type": "text"
      },
      "source": [
        "# Set up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGfpsxXojXLC",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "\"\"\"Script to download images from bing search api.\"\"\"\n",
        "\n",
        "\n",
        "from requests import exceptions\n",
        "import requests\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "# set up for search api\n",
        "\n",
        "api_key = \"\"\n",
        "max_results = 500\n",
        "group_size = 50\n",
        "\n",
        "url = \"https://api.cognitive.microsoft.com/bing/v7.0/images/search\"\n",
        "\n",
        "# collating exceptions that may occur during download process\n",
        "\n",
        "EXCEPTIONS = set([\n",
        "    IOError,\n",
        "    exceptions.RequestException,\n",
        "    exceptions.HTTPError,\n",
        "    exceptions.ConnectionError,\n",
        "    exceptions.Timeout\n",
        "])\n",
        "\n",
        "term = 'red shirt'\n",
        "headers = {\"Ocp-Apim-Subscription-Key\": api_key}\n",
        "params = {\"q\": term, \"offset\": 0, \"count\": group_size}\n",
        "output = 'data/'\n",
        "\n",
        "print(\"Searching bing for '{}'\".format(term))\n",
        "search = requests.get(url, headers=headers, params=params)\n",
        "search.raise_for_status()\n",
        "\n",
        "results = search.json()\n",
        "est_results = min(results['totalEstimatedMatches'], max_results)\n",
        "print(\"{} total results for '{}'\".format(est_results, term))\n",
        "\n",
        "total = 0\n",
        "\n",
        "for offset in range(0, est_results, group_size):\n",
        "    print('making request for group {}-{} for {}...'.format(offset, offset + group_size, est_results))\n",
        "    params['offset'] = offset\n",
        "    search = requests.get(url, headers=headers, params=params)\n",
        "    search.raise_for_status()\n",
        "    results = search.json()\n",
        "    print(\"Saving images for group {}-{} of {}...\".format(offset, offset + group_size, est_results))\n",
        "    for v in results[\"value\"]:\n",
        "        try:\n",
        "            # fetching the images\n",
        "            r = requests.get(v[\"contentUrl\"], timeout=30)\n",
        "\n",
        "            ext = v[\"contentUrl\"][v[\"contentUrl\"].rfind(\".\"):]\n",
        "            p = os.path.sep.join([output, \"{}{}\".format(str(total).zfill(8), ext)])\n",
        "\n",
        "            with open(p, \"wb\") as f:\n",
        "                f.write(r.content)\n",
        "\n",
        "            try:\n",
        "                image = cv2.imread(p)\n",
        "                if image is None:\n",
        "                    os.remove(p)\n",
        "                    continue\n",
        "                total += 1\n",
        "            except Exception as e:\n",
        "                os.remove(p)\n",
        "        except Exception as e:\n",
        "            if type(e) in EXCEPTIONS:\n",
        "                continue\n",
        "\n",
        "\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaSyWerj3pWK",
        "colab_type": "text"
      },
      "source": [
        "# Downloading File from gdrive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geKb0HGh3teL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "bb5b768b-e0bc-4724-b627-d7dcae48d3d1"
      },
      "source": [
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▎                               | 10kB 27.8MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 3.3MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 4.9MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 3.1MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 3.9MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 4.6MB/s eta 0:00:01\r\u001b[K     |██▎                             | 71kB 5.3MB/s eta 0:00:01\r\u001b[K     |██▋                             | 81kB 6.0MB/s eta 0:00:01\r\u001b[K     |███                             | 92kB 6.6MB/s eta 0:00:01\r\u001b[K     |███▎                            | 102kB 5.1MB/s eta 0:00:01\r\u001b[K     |███▋                            | 112kB 5.1MB/s eta 0:00:01\r\u001b[K     |████                            | 122kB 5.1MB/s eta 0:00:01\r\u001b[K     |████▎                           | 133kB 5.1MB/s eta 0:00:01\r\u001b[K     |████▋                           | 143kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████                           | 153kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 163kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 174kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████                          | 184kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 194kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 204kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████                         | 215kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 225kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 235kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████                        | 245kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 256kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 266kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████                       | 276kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 286kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 296kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████                      | 307kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 317kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 327kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████                     | 337kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 348kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 358kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████                    | 368kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 378kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 389kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 399kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 409kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 419kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 430kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 440kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 450kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 460kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 471kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 481kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████                | 491kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 501kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 512kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 522kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 532kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 542kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 552kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 563kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 573kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 583kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 593kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 604kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 614kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 624kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 634kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 645kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 655kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 665kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 675kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 686kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 696kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 706kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 716kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 727kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 737kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 747kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 757kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 768kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 778kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 788kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 798kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 808kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 819kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 829kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 839kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 849kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 860kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 870kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 880kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 890kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 901kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 911kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 921kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 931kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 942kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 952kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 962kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 972kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 983kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 993kB 5.1MB/s \n",
            "\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXET-7Nx3tYT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cacc535c-9470-470b-c25d-fa8136c00837"
      },
      "source": [
        "\n",
        "# file https://drive.google.com/file/d/1euHqg4kBBPtQIjfh8a6XOd7k01ps8F59/view?usp=sharing\n",
        "\n",
        "file_id = '1euHqg4kBBPtQIjfh8a6XOd7k01ps8F59'\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "print('Downloaded content \"{}\"'.format(downloaded.GetContentFile('black_jeans.zip')))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloaded content \"None\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTFzM3XOjW87",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir data\n",
        "!unzip -d data/ black_jeans.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Faw21gWojnmF",
        "colab_type": "text"
      },
      "source": [
        "# Data Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5kEGCAojlUM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "39debdc7-6cef-4ebf-8581-42ddc0405caf"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator, img_to_array\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import numpy as np\n",
        "import random\n",
        "import cv2\n",
        "import os\n",
        "from sklearn.preprocessing import MultiLabelBinarizer"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8LkEQOtAoir",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "edf2bd0b-5ae1-46d4-b8c1-7f7098423ebe"
      },
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NUvim0K7MPi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_path = 'data/*/*'\n",
        "image_paths = glob.glob(data_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NutyjiG7MLx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "b7cff4cc-0151-4436-c2a6-1507322d8db2"
      },
      "source": [
        "image_paths[:5]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['data/blue_jeans/00000392.jpeg',\n",
              " 'data/blue_jeans/00000403.jpeg',\n",
              " 'data/blue_jeans/00000315.jpeg',\n",
              " 'data/blue_jeans/00000242.jpeg',\n",
              " 'data/blue_jeans/00000324.jpeg']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVXJfx5k7MJA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "b1f161c6-6a21-4d8c-ea62-76577a5197af"
      },
      "source": [
        "np.random.seed(0)\n",
        "np.random.shuffle(image_paths)\n",
        "image_paths[:5]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['data/red_dress/00000244.jpg',\n",
              " 'data/blue_jeans/00000016.jpg',\n",
              " 'data/blue_dress/00000193.JPG',\n",
              " 'data/black_jeans/00000080.jpg',\n",
              " 'data/red_dress/00000127.jpg']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYZI2NmaBcJp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_dims = (96, 96, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ysk6sH7ZBoxi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5550496c-0006-4048-be38-e7d3c01a4bee"
      },
      "source": [
        "image_paths[0].split('/')[1], image_paths[0].split('/')[1].split(\"_\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('red_dress', ['red', 'dress'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gn1PmHGgB6C9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "94add6ea-6b09-488d-f59c-2a881f5a9e20"
      },
      "source": [
        "image_paths[0].split(os.path.sep)[-2].split(\"_\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['red', 'dress']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsRoIxXTBFcn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c38c6171-eee8-4795-be2e-f694615d455c"
      },
      "source": [
        "data = []\n",
        "labels = []\n",
        "\n",
        "for img_path in image_paths:\n",
        "  img = cv2.imread(img_path)\n",
        "  img = cv2.resize(img, (image_dims[0], image_dims[1]))\n",
        "  img = img_to_array(img)\n",
        "  data.append(img)\n",
        "  \n",
        "  # extracting labels\n",
        "  label = img_path.split(os.path.sep)[-2].split(\"_\")\n",
        "  labels.append(label)\n",
        "  \n",
        "# scaling the pixels to the range [0, 1]\n",
        "\n",
        "data = np.array(data, dtype=np.float32) / 255.0\n",
        "labels = np.array(labels)\n",
        "\n",
        "print(\"data matrix: {} images ({:2f}MB)\".format(len(image_paths), data.nbytes/(1024 * 1000.0)))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data matrix: 2454 images (265.032000MB)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-VypEdbBFaE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "222879be-cab8-46a1-c2b6-72d29f3f7e8f"
      },
      "source": [
        "data.shape, labels.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2454, 96, 96, 3), (2454, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtRmh5rPDM6x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "c2036ad7-83eb-4eb0-8ee7-fe36fb48750f"
      },
      "source": [
        "# binarization of the labels\n",
        "\n",
        "mlb = MultiLabelBinarizer()\n",
        "labels = mlb.fit_transform(labels)\n",
        "\n",
        "for (i, label) in enumerate(mlb.classes_):\n",
        "  print(\"{} {}\".format(i + 1, label))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 black\n",
            "2 blue\n",
            "3 dress\n",
            "4 jeans\n",
            "5 red\n",
            "6 shirt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0L5R6PB2DM4Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9b9ce505-479f-4e59-d56f-984154e663c9"
      },
      "source": [
        "labels.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2454, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUMXPYn5BFXe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "afc8e167-3af3-489a-e387-3339b9da7b0a"
      },
      "source": [
        "# spliting into train and test from data, labels\n",
        "x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1963, 96, 96, 3), (1963, 6), (491, 96, 96, 3), (491, 6))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhtoQUXkEm06",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "23ac8032-a208-4284-941d-cfb140dd7395"
      },
      "source": [
        "# splitting into train and validation from x_test, y_test\n",
        "\n",
        "x_test, x_val, y_test, y_val = train_test_split(x_test, y_test, test_size=0.2, random_state=42)\n",
        "\n",
        "x_test.shape, y_test.shape, x_val.shape, y_val.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((392, 96, 96, 3), (392, 6), (99, 96, 96, 3), (99, 6))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5Ym4rkvFLvI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data augmentation\n",
        "\n",
        "aug = ImageDataGenerator(\n",
        "    rotation_range=35,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode=\"nearest\"\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQZezb0t7MfR",
        "colab_type": "text"
      },
      "source": [
        "# Model\n",
        "\n",
        "https://arxiv.org/pdf/1409.1556/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgsD2Wf37PTa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "from keras.layers.core import Activation, Flatten, Dropout, Dense\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8re-A8VH7xNd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# building the model a smaller version of vgg19 as mentioned in the research paper.\n",
        "\n",
        "def build_model():\n",
        "  \"\"\"Function to create a model.\"\"\"\n",
        "  input_shape = x_train.shape[1:]\n",
        "  \n",
        "  model = Sequential()\n",
        "  \n",
        "  # conv => relu => pool\n",
        "  model.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=input_shape))\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size=(3, 3)))\n",
        "  model.add(Dropout(0.25))\n",
        "  \n",
        "  # (conv => relu) * 2 => Pool\n",
        "  for i in range(2):\n",
        "    model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "  \n",
        "  # (conv => relu) * 2 => Pool\n",
        "  for i in range(2):\n",
        "    model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "  \n",
        "  # FC => relu layers\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(1024))\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.5))\n",
        "  \n",
        "  # classifier layer\n",
        "  model.add(Dense(labels.shape[1]))\n",
        "  model.add(Activation('softmax'))\n",
        "  \n",
        "  return model\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riXxNGPQG3Xn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "50fe8654-e7b7-4978-fd6d-efe04d2c3460"
      },
      "source": [
        "model = build_model()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMv6Mv7-G3Q7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1088
        },
        "outputId": "85abb9cd-4c09-42ee-ecee-a9ac26004d86"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 96, 96, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 96, 96, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 96, 96, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 32, 32, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 32, 32, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 32, 32, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 32, 32, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 16, 16, 128)       73856     \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 16, 16, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 16, 16, 128)       147584    \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 16, 16, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1024)              8389632   \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 1024)              4096      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 6)                 6150      \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 6)                 0         \n",
            "=================================================================\n",
            "Total params: 8,679,302\n",
            "Trainable params: 8,676,422\n",
            "Non-trainable params: 2,880\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxEXOlai-ODg",
        "colab_type": "text"
      },
      "source": [
        "# Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PG44vun3-N3r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BkLAYYu-ZSp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMwHSz6H-N0o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 100\n",
        "init_lr = 1e-3\n",
        "batch_size = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEuaEQbNHejv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = Adam(lr=init_lr, decay=init_lr/epochs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIuNxgHD-Nx6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xytVktURHmWc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_summary(H, epochs):\n",
        "  \"\"\"Function to plot the training summary.\"\"\"\n",
        "  plt.style.use(\"ggplot\")\n",
        "  plt.figure(figsize=(9, 6))\n",
        "  N = epochs\n",
        "  \n",
        "  for i in zip(['loss', 'val_loss', 'acc', 'val_acc'], ['train_loss', 'val_loss', 'train_acc', 'val_acc']):\n",
        "    plt.plot(np.arange(0, N), H.history[i[0]], label=i[1])\n",
        "  plt.title(\"Training loss and Accuracy\")\n",
        "  plt.xlabel('Epoch #')\n",
        "  plt.ylabel('Loss / Accuracy')\n",
        "  plt.legend(loc=\"lower left\")\n",
        "  plt.savefig(\"training.png\")\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYH1SQMtHciD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "daeefa45-6672-4f84-8e78-928bb4db4648"
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 13197732917864597308\n",
            ", name: \"/device:XLA_CPU:0\"\n",
            "device_type: \"XLA_CPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 7981264002938954569\n",
            "physical_device_desc: \"device: XLA_CPU device\"\n",
            ", name: \"/device:XLA_GPU:0\"\n",
            "device_type: \"XLA_GPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 5823041894180857314\n",
            "physical_device_desc: \"device: XLA_GPU device\"\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 14800692839\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 1531131060870561864\n",
            "physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIww_iq5IW-5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d97a6c4f-3524-48b3-ba0e-756f0f7225e2"
      },
      "source": [
        "K.tensorflow_backend._get_available_gpus()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/job:localhost/replica:0/task:0/device:GPU:0']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Jermsf3JDv3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3488
        },
        "outputId": "b9fa55f3-62aa-4ed5-f9df-7f385c871479"
      },
      "source": [
        "H = model.fit_generator(\n",
        "    aug.flow(x_train, y_train, batch_size=batch_size),\n",
        "    validation_data=(x_val, y_val),\n",
        "    steps_per_epoch=len(x_train) // batch_size,\n",
        "    epochs=epochs,\n",
        "    verbose=2\n",
        ")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/100\n",
            " - 9s - loss: 0.7236 - acc: 0.7612 - val_loss: 0.6148 - val_acc: 0.7896\n",
            "Epoch 2/100\n",
            " - 4s - loss: 0.5502 - acc: 0.7805 - val_loss: 0.4736 - val_acc: 0.8182\n",
            "Epoch 3/100\n",
            " - 4s - loss: 0.5030 - acc: 0.7898 - val_loss: 0.4024 - val_acc: 0.8047\n",
            "Epoch 4/100\n",
            " - 4s - loss: 0.4735 - acc: 0.7907 - val_loss: 0.3844 - val_acc: 0.8081\n",
            "Epoch 5/100\n",
            " - 4s - loss: 0.4542 - acc: 0.7928 - val_loss: 0.3564 - val_acc: 0.8047\n",
            "Epoch 6/100\n",
            " - 4s - loss: 0.4162 - acc: 0.8001 - val_loss: 0.3727 - val_acc: 0.8047\n",
            "Epoch 7/100\n",
            " - 4s - loss: 0.4081 - acc: 0.8015 - val_loss: 0.3619 - val_acc: 0.7929\n",
            "Epoch 8/100\n",
            " - 4s - loss: 0.4025 - acc: 0.7995 - val_loss: 0.3475 - val_acc: 0.8165\n",
            "Epoch 9/100\n",
            " - 4s - loss: 0.3783 - acc: 0.8057 - val_loss: 0.3442 - val_acc: 0.7946\n",
            "Epoch 10/100\n",
            " - 4s - loss: 0.3915 - acc: 0.7974 - val_loss: 0.3387 - val_acc: 0.7946\n",
            "Epoch 11/100\n",
            " - 4s - loss: 0.3791 - acc: 0.8018 - val_loss: 0.3382 - val_acc: 0.8148\n",
            "Epoch 12/100\n",
            " - 4s - loss: 0.3659 - acc: 0.8020 - val_loss: 0.3103 - val_acc: 0.8114\n",
            "Epoch 13/100\n",
            " - 4s - loss: 0.3608 - acc: 0.8076 - val_loss: 0.3228 - val_acc: 0.8131\n",
            "Epoch 14/100\n",
            " - 4s - loss: 0.3535 - acc: 0.8061 - val_loss: 0.3672 - val_acc: 0.8165\n",
            "Epoch 15/100\n",
            " - 4s - loss: 0.3478 - acc: 0.8073 - val_loss: 0.3026 - val_acc: 0.8114\n",
            "Epoch 16/100\n",
            " - 4s - loss: 0.3384 - acc: 0.8088 - val_loss: 0.3293 - val_acc: 0.8131\n",
            "Epoch 17/100\n",
            " - 4s - loss: 0.3333 - acc: 0.8082 - val_loss: 0.3562 - val_acc: 0.8013\n",
            "Epoch 18/100\n",
            " - 4s - loss: 0.3379 - acc: 0.8082 - val_loss: 0.3306 - val_acc: 0.8030\n",
            "Epoch 19/100\n",
            " - 4s - loss: 0.3408 - acc: 0.8042 - val_loss: 0.3166 - val_acc: 0.8081\n",
            "Epoch 20/100\n",
            " - 4s - loss: 0.3303 - acc: 0.8088 - val_loss: 0.3246 - val_acc: 0.8098\n",
            "Epoch 21/100\n",
            " - 4s - loss: 0.3360 - acc: 0.8057 - val_loss: 0.3762 - val_acc: 0.8081\n",
            "Epoch 22/100\n",
            " - 4s - loss: 0.3348 - acc: 0.8077 - val_loss: 0.3111 - val_acc: 0.8098\n",
            "Epoch 23/100\n",
            " - 4s - loss: 0.3265 - acc: 0.8071 - val_loss: 0.3138 - val_acc: 0.8131\n",
            "Epoch 24/100\n",
            " - 4s - loss: 0.3283 - acc: 0.8084 - val_loss: 0.3315 - val_acc: 0.8098\n",
            "Epoch 25/100\n",
            " - 4s - loss: 0.3238 - acc: 0.8097 - val_loss: 0.2907 - val_acc: 0.8199\n",
            "Epoch 26/100\n",
            " - 5s - loss: 0.3272 - acc: 0.8089 - val_loss: 0.3051 - val_acc: 0.8165\n",
            "Epoch 27/100\n",
            " - 4s - loss: 0.3204 - acc: 0.8095 - val_loss: 0.3137 - val_acc: 0.8182\n",
            "Epoch 28/100\n",
            " - 4s - loss: 0.3259 - acc: 0.8110 - val_loss: 0.3206 - val_acc: 0.8131\n",
            "Epoch 29/100\n",
            " - 4s - loss: 0.3189 - acc: 0.8094 - val_loss: 0.3192 - val_acc: 0.8215\n",
            "Epoch 30/100\n",
            " - 4s - loss: 0.3132 - acc: 0.8143 - val_loss: 0.3222 - val_acc: 0.8148\n",
            "Epoch 31/100\n",
            " - 4s - loss: 0.3170 - acc: 0.8103 - val_loss: 0.3475 - val_acc: 0.8131\n",
            "Epoch 32/100\n",
            " - 4s - loss: 0.3134 - acc: 0.8128 - val_loss: 0.3055 - val_acc: 0.8064\n",
            "Epoch 33/100\n",
            " - 4s - loss: 0.3124 - acc: 0.8127 - val_loss: 0.3547 - val_acc: 0.8182\n",
            "Epoch 34/100\n",
            " - 4s - loss: 0.3191 - acc: 0.8114 - val_loss: 0.2937 - val_acc: 0.8249\n",
            "Epoch 35/100\n",
            " - 4s - loss: 0.3127 - acc: 0.8127 - val_loss: 0.3017 - val_acc: 0.8215\n",
            "Epoch 36/100\n",
            " - 4s - loss: 0.3070 - acc: 0.8122 - val_loss: 0.2986 - val_acc: 0.8182\n",
            "Epoch 37/100\n",
            " - 4s - loss: 0.3150 - acc: 0.8107 - val_loss: 0.3235 - val_acc: 0.8114\n",
            "Epoch 38/100\n",
            " - 4s - loss: 0.3078 - acc: 0.8128 - val_loss: 0.3432 - val_acc: 0.8131\n",
            "Epoch 39/100\n",
            " - 4s - loss: 0.3093 - acc: 0.8124 - val_loss: 0.3905 - val_acc: 0.7912\n",
            "Epoch 40/100\n",
            " - 4s - loss: 0.3091 - acc: 0.8130 - val_loss: 0.3475 - val_acc: 0.8047\n",
            "Epoch 41/100\n",
            " - 4s - loss: 0.3108 - acc: 0.8117 - val_loss: 0.3041 - val_acc: 0.8148\n",
            "Epoch 42/100\n",
            " - 4s - loss: 0.3023 - acc: 0.8138 - val_loss: 0.3793 - val_acc: 0.7963\n",
            "Epoch 43/100\n",
            " - 4s - loss: 0.3125 - acc: 0.8104 - val_loss: 0.3168 - val_acc: 0.7997\n",
            "Epoch 44/100\n",
            " - 4s - loss: 0.3026 - acc: 0.8155 - val_loss: 0.4559 - val_acc: 0.7744\n",
            "Epoch 45/100\n",
            " - 4s - loss: 0.3044 - acc: 0.8132 - val_loss: 0.2975 - val_acc: 0.8165\n",
            "Epoch 46/100\n",
            " - 4s - loss: 0.3067 - acc: 0.8129 - val_loss: 0.3114 - val_acc: 0.8114\n",
            "Epoch 47/100\n",
            " - 4s - loss: 0.3019 - acc: 0.8136 - val_loss: 0.3343 - val_acc: 0.8131\n",
            "Epoch 48/100\n",
            " - 4s - loss: 0.3000 - acc: 0.8136 - val_loss: 0.3346 - val_acc: 0.7997\n",
            "Epoch 49/100\n",
            " - 4s - loss: 0.3018 - acc: 0.8149 - val_loss: 0.3150 - val_acc: 0.8114\n",
            "Epoch 50/100\n",
            " - 4s - loss: 0.2957 - acc: 0.8165 - val_loss: 0.3126 - val_acc: 0.8199\n",
            "Epoch 51/100\n",
            " - 4s - loss: 0.3012 - acc: 0.8137 - val_loss: 0.3861 - val_acc: 0.8131\n",
            "Epoch 52/100\n",
            " - 4s - loss: 0.2994 - acc: 0.8149 - val_loss: 0.3213 - val_acc: 0.8199\n",
            "Epoch 53/100\n",
            " - 4s - loss: 0.2937 - acc: 0.8158 - val_loss: 0.3591 - val_acc: 0.8199\n",
            "Epoch 54/100\n",
            " - 4s - loss: 0.2933 - acc: 0.8152 - val_loss: 0.3253 - val_acc: 0.8148\n",
            "Epoch 55/100\n",
            " - 4s - loss: 0.2884 - acc: 0.8160 - val_loss: 0.3217 - val_acc: 0.8199\n",
            "Epoch 56/100\n",
            " - 4s - loss: 0.2925 - acc: 0.8184 - val_loss: 0.3729 - val_acc: 0.8131\n",
            "Epoch 57/100\n",
            " - 4s - loss: 0.2894 - acc: 0.8180 - val_loss: 0.3064 - val_acc: 0.8030\n",
            "Epoch 58/100\n",
            " - 4s - loss: 0.2877 - acc: 0.8180 - val_loss: 0.3549 - val_acc: 0.8131\n",
            "Epoch 59/100\n",
            " - 4s - loss: 0.2937 - acc: 0.8178 - val_loss: 0.3767 - val_acc: 0.7980\n",
            "Epoch 60/100\n",
            " - 4s - loss: 0.2902 - acc: 0.8164 - val_loss: 0.3670 - val_acc: 0.8165\n",
            "Epoch 61/100\n",
            " - 4s - loss: 0.2866 - acc: 0.8161 - val_loss: 0.3132 - val_acc: 0.8232\n",
            "Epoch 62/100\n",
            " - 4s - loss: 0.2875 - acc: 0.8171 - val_loss: 0.3126 - val_acc: 0.8148\n",
            "Epoch 63/100\n",
            " - 4s - loss: 0.2887 - acc: 0.8170 - val_loss: 0.3286 - val_acc: 0.8030\n",
            "Epoch 64/100\n",
            " - 4s - loss: 0.2967 - acc: 0.8141 - val_loss: 0.2885 - val_acc: 0.8098\n",
            "Epoch 65/100\n",
            " - 4s - loss: 0.2880 - acc: 0.8182 - val_loss: 0.2982 - val_acc: 0.8131\n",
            "Epoch 66/100\n",
            " - 4s - loss: 0.2890 - acc: 0.8178 - val_loss: 0.3108 - val_acc: 0.8182\n",
            "Epoch 67/100\n",
            " - 4s - loss: 0.2931 - acc: 0.8167 - val_loss: 0.3013 - val_acc: 0.8182\n",
            "Epoch 68/100\n",
            " - 4s - loss: 0.2900 - acc: 0.8187 - val_loss: 0.3743 - val_acc: 0.8030\n",
            "Epoch 69/100\n",
            " - 4s - loss: 0.2955 - acc: 0.8179 - val_loss: 0.3243 - val_acc: 0.8081\n",
            "Epoch 70/100\n",
            " - 4s - loss: 0.3051 - acc: 0.8138 - val_loss: 0.3402 - val_acc: 0.8165\n",
            "Epoch 71/100\n",
            " - 4s - loss: 0.2967 - acc: 0.8157 - val_loss: 0.3666 - val_acc: 0.8081\n",
            "Epoch 72/100\n",
            " - 5s - loss: 0.2988 - acc: 0.8157 - val_loss: 0.3927 - val_acc: 0.7997\n",
            "Epoch 73/100\n",
            " - 5s - loss: 0.3056 - acc: 0.8108 - val_loss: 0.3375 - val_acc: 0.8165\n",
            "Epoch 74/100\n",
            " - 4s - loss: 0.2929 - acc: 0.8180 - val_loss: 0.3745 - val_acc: 0.8013\n",
            "Epoch 75/100\n",
            " - 4s - loss: 0.2928 - acc: 0.8156 - val_loss: 0.2978 - val_acc: 0.8249\n",
            "Epoch 76/100\n",
            " - 4s - loss: 0.2894 - acc: 0.8150 - val_loss: 0.3093 - val_acc: 0.8148\n",
            "Epoch 77/100\n",
            " - 4s - loss: 0.2857 - acc: 0.8180 - val_loss: 0.3175 - val_acc: 0.8114\n",
            "Epoch 78/100\n",
            " - 4s - loss: 0.2830 - acc: 0.8163 - val_loss: 0.2875 - val_acc: 0.8165\n",
            "Epoch 79/100\n",
            " - 4s - loss: 0.2775 - acc: 0.8201 - val_loss: 0.3156 - val_acc: 0.8182\n",
            "Epoch 80/100\n",
            " - 4s - loss: 0.2814 - acc: 0.8204 - val_loss: 0.3025 - val_acc: 0.8232\n",
            "Epoch 81/100\n",
            " - 4s - loss: 0.2840 - acc: 0.8169 - val_loss: 0.2911 - val_acc: 0.8114\n",
            "Epoch 82/100\n",
            " - 4s - loss: 0.2862 - acc: 0.8187 - val_loss: 0.3672 - val_acc: 0.8098\n",
            "Epoch 83/100\n",
            " - 4s - loss: 0.2839 - acc: 0.8173 - val_loss: 0.2890 - val_acc: 0.8215\n",
            "Epoch 84/100\n",
            " - 4s - loss: 0.2792 - acc: 0.8195 - val_loss: 0.3188 - val_acc: 0.8199\n",
            "Epoch 85/100\n",
            " - 4s - loss: 0.2817 - acc: 0.8193 - val_loss: 0.3068 - val_acc: 0.8182\n",
            "Epoch 86/100\n",
            " - 4s - loss: 0.2788 - acc: 0.8195 - val_loss: 0.2927 - val_acc: 0.8165\n",
            "Epoch 87/100\n",
            " - 4s - loss: 0.2743 - acc: 0.8188 - val_loss: 0.2866 - val_acc: 0.8215\n",
            "Epoch 88/100\n",
            " - 4s - loss: 0.2862 - acc: 0.8177 - val_loss: 0.3538 - val_acc: 0.8182\n",
            "Epoch 89/100\n",
            " - 4s - loss: 0.2986 - acc: 0.8161 - val_loss: 0.2880 - val_acc: 0.8148\n",
            "Epoch 90/100\n",
            " - 4s - loss: 0.2928 - acc: 0.8162 - val_loss: 0.3459 - val_acc: 0.8232\n",
            "Epoch 91/100\n",
            " - 4s - loss: 0.2907 - acc: 0.8175 - val_loss: 0.3231 - val_acc: 0.8232\n",
            "Epoch 92/100\n",
            " - 4s - loss: 0.2819 - acc: 0.8192 - val_loss: 0.2920 - val_acc: 0.8199\n",
            "Epoch 93/100\n",
            " - 4s - loss: 0.2859 - acc: 0.8188 - val_loss: 0.3105 - val_acc: 0.8098\n",
            "Epoch 94/100\n",
            " - 4s - loss: 0.2813 - acc: 0.8176 - val_loss: 0.3013 - val_acc: 0.8148\n",
            "Epoch 95/100\n",
            " - 4s - loss: 0.2786 - acc: 0.8190 - val_loss: 0.4135 - val_acc: 0.7896\n",
            "Epoch 96/100\n",
            " - 4s - loss: 0.2838 - acc: 0.8203 - val_loss: 0.2926 - val_acc: 0.7980\n",
            "Epoch 97/100\n",
            " - 4s - loss: 0.2848 - acc: 0.8178 - val_loss: 0.2828 - val_acc: 0.8148\n",
            "Epoch 98/100\n",
            " - 4s - loss: 0.2814 - acc: 0.8180 - val_loss: 0.2886 - val_acc: 0.8283\n",
            "Epoch 99/100\n",
            " - 4s - loss: 0.2778 - acc: 0.8200 - val_loss: 0.2889 - val_acc: 0.8232\n",
            "Epoch 100/100\n",
            " - 4s - loss: 0.2716 - acc: 0.8214 - val_loss: 0.2782 - val_acc: 0.8232\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSaQrvyqJbSZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_summary(H, epochs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEEM2SV5JiA6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9e3a01fd-e660-47f9-d26c-28cc39e8f6d1"
      },
      "source": [
        "model.evaluate(x_test, y_test, verbose=2)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.267914250797155, 0.824404742036547]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GH5vmjkJmJS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.image as mpimg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCdVG3GbLdfb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = mpimg.imread('training.png')\n",
        "img_plot = plt.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTww4rWsLl6i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "3e9fb31e-10c7-4d70-b358-a10dfb420c31"
      },
      "source": [
        "!wget https://images.homedepot-static.com/productImages/6fff137a-4a9d-43da-8971-347ec7dc994a/svn/blue-arctic-cove-work-shirts-mac555l-64_1000.jpg"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-22 06:57:37--  https://images.homedepot-static.com/productImages/6fff137a-4a9d-43da-8971-347ec7dc994a/svn/blue-arctic-cove-work-shirts-mac555l-64_1000.jpg\n",
            "Resolving images.homedepot-static.com (images.homedepot-static.com)... 35.186.226.36\n",
            "Connecting to images.homedepot-static.com (images.homedepot-static.com)|35.186.226.36|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 43994 (43K) [image/jpeg]\n",
            "Saving to: ‘blue-arctic-cove-work-shirts-mac555l-64_1000.jpg’\n",
            "\n",
            "\r          blue-arct   0%[                    ]       0  --.-KB/s               \rblue-arctic-cove-wo 100%[===================>]  42.96K  --.-KB/s    in 0.06s   \n",
            "\n",
            "2019-05-22 06:57:37 (758 KB/s) - ‘blue-arctic-cove-work-shirts-mac555l-64_1000.jpg’ saved [43994/43994]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7Jzp5buVcc0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faPdcBhRVLf4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = mpimg.imread('blue-arctic-cove-work-shirts-mac555l-64_1000.jpg')\n",
        "img_plot = plt.imshow(img)\n",
        "plt.show();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8X4R-ZOtV9OO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c61c0978-f394-4466-b76b-7475a0bf15c4"
      },
      "source": [
        "img = cv2.imread('blue-arctic-cove-work-shirts-mac555l-64_1000.jpg')\n",
        "img = cv2.resize(img, (image_dims[0], image_dims[1]))\n",
        "img = img_to_array(img)\n",
        "test = np.array([img], dtype=np.float32) / 255.0\n",
        "test.shape"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 96, 96, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gq6f2jBpWOKY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction = model.predict(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ea95mCnNWmYT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d126f881-e43d-4975-f148-b9d2da20bd99"
      },
      "source": [
        "prediction"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.3087600e-04, 5.4833102e-01, 2.1373096e-03, 2.4988172e-03,\n",
              "        7.9513859e-04, 4.4600683e-01]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ufwysm4pWsHt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "0b4d47d7-70fc-4e62-e4e7-255ce5a887ff"
      },
      "source": [
        "for (i, label) in enumerate(mlb.classes_):\n",
        "  print(\"{} {}\".format(i + 1, label))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 black\n",
            "2 blue\n",
            "3 dress\n",
            "4 jeans\n",
            "5 red\n",
            "6 shirt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-C8U_LKQW7_-",
        "colab_type": "text"
      },
      "source": [
        "highest is 2 , and 6 which is correct blue shirt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlI4WV626CkK",
        "colab_type": "text"
      },
      "source": [
        "# Multiple output multiple losses\n",
        "\n",
        "**Data processing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTr1Jqrx6CaM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import img_to_array, ImageDataGenerator\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrM9BszS6CQp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 50\n",
        "init_lr = 1e-3\n",
        "batch_size = 32\n",
        "image_dims = (96, 96, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5XqbC786CHU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_path  = 'data/*/*'\n",
        "image_paths = glob.glob(data_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leMEW-HVW6d-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(42)\n",
        "np.random.shuffle(image_paths)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNtI5rV-UR3p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d6f36dbd-9874-41ca-95be-24fc755f90f3"
      },
      "source": [
        "data = []\n",
        "category_labels = []\n",
        "color_labels = []\n",
        "\n",
        "for img_path in image_paths:\n",
        "  img = cv2.imread(img_path)\n",
        "  img = cv2.resize(img, (image_dims[1], image_dims[0]))\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  img = img_to_array(img)\n",
        "  data.append(img)\n",
        "  \n",
        "  (colr, cat) = img_path.split(os.path.sep)[-2].split(\"_\")\n",
        "  category_labels.append(cat)\n",
        "  color_labels.append(colr)\n",
        "\n",
        "# scaling  the images\n",
        "data = np.array(data, dtype=np.float32) / 255.0\n",
        "print(\"data matrix: {} images ({:.2f}MB)\".format(len(img_path), data.nbytes / (1024 * 1000.0)))\n",
        "\n",
        "category_labels = np.array(category_labels)\n",
        "color_labels = np.array(color_labels)\n",
        "\n",
        "# binarization\n",
        "\n",
        "category_lb = LabelBinarizer()\n",
        "color_lb = LabelBinarizer()\n",
        "\n",
        "category_labels = category_lb.fit_transform(category_labels)\n",
        "color_labels = color_lb.fit_transform(color_labels)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data matrix: 29 images (265.03MB)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GLqAmONUR04",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3a8d9fbc-4791-4863-8d75-64bea21eac5b"
      },
      "source": [
        "data.shape, color_labels.shape, category_labels.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2454, 96, 96, 3), (2454, 3), (2454, 3))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZRNfRjiURyK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "885f9232-8438-4470-c5c4-a03192d19c01"
      },
      "source": [
        "x_train, x_test, y_train_cat, y_test_cat, y_train_col, y_test_col = train_test_split(data, category_labels, color_labels, test_size=0.2, shuffle=True, random_state=42)\n",
        "\n",
        "print(x_train.shape, x_test.shape)\n",
        "\n",
        "print(y_train_cat.shape, y_test_cat.shape, y_train_col.shape, y_test_col.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1963, 96, 96, 3) (491, 96, 96, 3)\n",
            "(1963, 3) (491, 3) (1963, 3) (491, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x28sni5j6NPr",
        "colab_type": "text"
      },
      "source": [
        "# Model input - output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19Pxtukx6-MK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "from keras.layers.core import Activation, Dropout, Lambda, Dense\n",
        "from keras.layers import Flatten, Input\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ayyv8L_16M56",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyNet:\n",
        "  \"\"\"Class to implement multi branch network category and color classificaiton.\"\"\"\n",
        "  \n",
        "  @staticmethod\n",
        "  def build_category_branch(inputs, num_categories, final_activation=\"softmax\", chan_dim=-1):\n",
        "    \"\"\"Function to build a category branched model.\"\"\"\n",
        "    # lambda layer to convert the 3 channel input to grayscale representation\n",
        "    x = Lambda(lambda c: tf.image.rgb_to_grayscale(c))(inputs)\n",
        "\n",
        "    # conv => relu => pool\n",
        "    x = Conv2D(32, (3, 3), padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization(axis=chan_dim)(x)\n",
        "    x = MaxPooling2D(pool_size=(3, 3))(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "\n",
        "    # conv => relu * 2 => Pool\n",
        "    for i in range(2):\n",
        "      x = Conv2D(128, (3, 3), padding=\"same\")(x)\n",
        "      x = Activation(\"relu\")(x)\n",
        "      x = BatchNormalization(axis=chan_dim)(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "\n",
        "    # define branch of output layers\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(256)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(num_categories)(x)\n",
        "    x = Activation(final_activation, name=\"category_output\")(x)\n",
        "\n",
        "    return x\n",
        "  \n",
        "  @staticmethod\n",
        "  def build_color_branch(inputs, num_color, final_activation=\"softmax\", chan_dim=-1):\n",
        "    \"\"\"Function to create color branch model.\"\"\"\n",
        "    \n",
        "    # conv => relu => pool\n",
        "    x = Conv2D(16, (3, 3), padding=\"same\")(inputs)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization(axis=chan_dim)(x)\n",
        "    x = MaxPooling2D(pool_size=(3, 3))(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "    \n",
        "    # conv => relu => pool => dropout * 2\n",
        "    for i in range(2):\n",
        "      x = Conv2D(32, (3, 3), padding=\"same\")(x)\n",
        "      x = Activation(\"relu\")(x)\n",
        "      x = BatchNormalization(axis=chan_dim)(x)\n",
        "      x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "      x = Dropout(0.25)(x)\n",
        "    \n",
        "    x = Flatten()(x)\n",
        "    x = Dense(128)(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(num_color)(x)\n",
        "    x = Activation(final_activation, name=\"color_output\")(x)\n",
        "    return x\n",
        "  \n",
        "  @staticmethod\n",
        "  def build(width, height, num_categories, num_colors, final_activation=\"softmax\"):\n",
        "    \"\"\"Function to build the model.\"\"\"\n",
        "    \n",
        "    input_shape = (height, width, 3)\n",
        "    chan_dim = -1\n",
        "    inputs = Input(shape=input_shape)\n",
        "    \n",
        "    category_branch = MyNet.build_category_branch(inputs, num_categories, final_activation=final_activation, chan_dim=chan_dim)\n",
        "    color_branch = MyNet.build_color_branch(inputs, num_colors, final_activation=final_activation, chan_dim=chan_dim)\n",
        "    \n",
        "    # model architecture\n",
        "    model = Model(\n",
        "        inputs=inputs,\n",
        "        outputs=[category_branch, color_branch],\n",
        "        name=\"clothingClassification\"\n",
        "    )\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkYshL8NZJd0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = MyNet.build(\n",
        "    96, 96,\n",
        "    num_categories=len(category_lb.classes_),\n",
        "    num_colors=len(color_lb.classes_),\n",
        "    final_activation=\"softmax\"\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8j9B6ZOmZlCm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1584
        },
        "outputId": "dcc0791b-7384-4279-c53b-595878f66227"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            (None, 96, 96, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 96, 96, 16)   448         input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 96, 96, 16)   0           conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 96, 96, 16)   64          activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "lambda_5 (Lambda)               (None, 96, 96, 1)    0           input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling2D) (None, 32, 32, 16)   0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 96, 96, 32)   320         lambda_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_22 (Dropout)            (None, 32, 32, 16)   0           max_pooling2d_12[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 96, 96, 32)   0           conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 32, 32, 32)   4640        dropout_22[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 96, 96, 32)   128         activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 32, 32, 32)   0           conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling2D) (None, 32, 32, 32)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 32, 32, 32)   128         activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_19 (Dropout)            (None, 32, 32, 32)   0           max_pooling2d_11[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling2D) (None, 16, 16, 32)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 32, 32, 128)  36992       dropout_19[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_23 (Dropout)            (None, 16, 16, 32)   0           max_pooling2d_13[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 32, 32, 128)  0           conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 32)   9248        dropout_23[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 32, 32, 128)  512         activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 32)   0           conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 32, 32, 128)  147584      batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 32)   128         activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 32, 32, 128)  0           conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling2D) (None, 8, 8, 32)     0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 32, 32, 128)  512         activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_24 (Dropout)            (None, 8, 8, 32)     0           max_pooling2d_14[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_20 (Dropout)            (None, 32, 32, 128)  0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "flatten_7 (Flatten)             (None, 2048)         0           dropout_24[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "flatten_6 (Flatten)             (None, 131072)       0           dropout_20[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_12 (Dense)                (None, 128)          262272      flatten_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_10 (Dense)                (None, 256)          33554688    flatten_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 128)          0           dense_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 256)          1024        dense_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 128)          512         activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_21 (Dropout)            (None, 256)          0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_25 (Dropout)            (None, 128)          0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_11 (Dense)                (None, 3)            771         dropout_21[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_13 (Dense)                (None, 3)            387         dropout_25[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "category_output (Activation)    (None, 3)            0           dense_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "color_output (Activation)       (None, 3)            0           dense_13[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 34,020,358\n",
            "Trainable params: 34,018,854\n",
            "Non-trainable params: 1,504\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3AVTRw6Zk3C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import plot_model\n",
        "plot_model(model, to_file='model.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcgMFruPa5WI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "d50c32fb-3992-446e-cf48-1c5743e83e6a"
      },
      "source": [
        "import matplotlib.image as mpimg\n",
        "img = mpimg.imread('model.png')\n",
        "img_plot = plt.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHsAAAD8CAYAAABXctsfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4jONvgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1QQW_omTprU",
        "colab_type": "text"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJ7NqEF7L67l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQNM044gKDiS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "losses = {\n",
        "    \"category_output\" : \"categorical_crossentropy\",\n",
        "    \"color_output\" : \"categorical_crossentropy\"\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIQOTAqhb446",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_weights = {\n",
        "    'category_output': 1.0,\n",
        "    'color_output': 1.0\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "achwyqdGcBnK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = Adam(lr=init_lr, decay=init_lr / epochs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1fExcpMcInL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=opt, loss=losses, loss_weights=loss_weights, metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsaJB42icSp1",
        "colab_type": "text"
      },
      "source": [
        "# Model branched Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lD5sNhCcRH9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1805
        },
        "outputId": "48fec0b2-503b-4fb4-ba32-8fe941868b73"
      },
      "source": [
        "H = model.fit(\n",
        "    x_train,\n",
        "    {'category_output': y_train_cat, \"color_output\":y_train_col},\n",
        "    validation_data=(\n",
        "        x_test,\n",
        "        {'category_output': y_test_cat, \"color_output\": y_test_col}\n",
        "    ),\n",
        "    epochs=epochs,\n",
        "    verbose=1\n",
        ")"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 1963 samples, validate on 491 samples\n",
            "Epoch 1/50\n",
            "1963/1963 [==============================] - 11s 6ms/step - loss: 1.3733 - category_output_loss: 1.0099 - color_output_loss: 0.3634 - category_output_acc: 0.7534 - color_output_acc: 0.8742 - val_loss: 0.8362 - val_category_output_loss: 0.6465 - val_color_output_loss: 0.1897 - val_category_output_acc: 0.8208 - val_color_output_acc: 0.9328\n",
            "Epoch 2/50\n",
            "1963/1963 [==============================] - 4s 2ms/step - loss: 0.6848 - category_output_loss: 0.5113 - color_output_loss: 0.1735 - category_output_acc: 0.8273 - color_output_acc: 0.9358 - val_loss: 0.5431 - val_category_output_loss: 0.4483 - val_color_output_loss: 0.0948 - val_category_output_acc: 0.8391 - val_color_output_acc: 0.9613\n",
            "Epoch 3/50\n",
            "1963/1963 [==============================] - 4s 2ms/step - loss: 0.5277 - category_output_loss: 0.3903 - color_output_loss: 0.1373 - category_output_acc: 0.8594 - color_output_acc: 0.9491 - val_loss: 0.5337 - val_category_output_loss: 0.4403 - val_color_output_loss: 0.0934 - val_category_output_acc: 0.8289 - val_color_output_acc: 0.9593\n",
            "Epoch 4/50\n",
            "1963/1963 [==============================] - 4s 2ms/step - loss: 0.4613 - category_output_loss: 0.3351 - color_output_loss: 0.1263 - category_output_acc: 0.8910 - color_output_acc: 0.9572 - val_loss: 0.6387 - val_category_output_loss: 0.5482 - val_color_output_loss: 0.0905 - val_category_output_acc: 0.8432 - val_color_output_acc: 0.9633\n",
            "Epoch 5/50\n",
            "1963/1963 [==============================] - 4s 2ms/step - loss: 0.3028 - category_output_loss: 0.2028 - color_output_loss: 0.1000 - category_output_acc: 0.9317 - color_output_acc: 0.9638 - val_loss: 0.4267 - val_category_output_loss: 0.3571 - val_color_output_loss: 0.0696 - val_category_output_acc: 0.8819 - val_color_output_acc: 0.9735\n",
            "Epoch 6/50\n",
            "1963/1963 [==============================] - 4s 2ms/step - loss: 0.3118 - category_output_loss: 0.2032 - color_output_loss: 0.1086 - category_output_acc: 0.9231 - color_output_acc: 0.9608 - val_loss: 0.4359 - val_category_output_loss: 0.2997 - val_color_output_loss: 0.1362 - val_category_output_acc: 0.8982 - val_color_output_acc: 0.9511\n",
            "Epoch 7/50\n",
            "1963/1963 [==============================] - 4s 2ms/step - loss: 0.2779 - category_output_loss: 0.1728 - color_output_loss: 0.1051 - category_output_acc: 0.9368 - color_output_acc: 0.9643 - val_loss: 0.5018 - val_category_output_loss: 0.4058 - val_color_output_loss: 0.0960 - val_category_output_acc: 0.8676 - val_color_output_acc: 0.9633\n",
            "Epoch 8/50\n",
            "1963/1963 [==============================] - 4s 2ms/step - loss: 0.2333 - category_output_loss: 0.1361 - color_output_loss: 0.0972 - category_output_acc: 0.9542 - color_output_acc: 0.9684 - val_loss: 0.8230 - val_category_output_loss: 0.7378 - val_color_output_loss: 0.0852 - val_category_output_acc: 0.7882 - val_color_output_acc: 0.9613\n",
            "Epoch 9/50\n",
            "1963/1963 [==============================] - 4s 2ms/step - loss: 0.1934 - category_output_loss: 0.1042 - color_output_loss: 0.0892 - category_output_acc: 0.9684 - color_output_acc: 0.9694 - val_loss: 0.4599 - val_category_output_loss: 0.3577 - val_color_output_loss: 0.1022 - val_category_output_acc: 0.8880 - val_color_output_acc: 0.9633\n",
            "Epoch 10/50\n",
            "1963/1963 [==============================] - 4s 2ms/step - loss: 0.1752 - category_output_loss: 0.0868 - color_output_loss: 0.0884 - category_output_acc: 0.9705 - color_output_acc: 0.9684 - val_loss: 0.4981 - val_category_output_loss: 0.3908 - val_color_output_loss: 0.1073 - val_category_output_acc: 0.8819 - val_color_output_acc: 0.9593\n",
            "Epoch 11/50\n",
            "1963/1963 [==============================] - 4s 2ms/step - loss: 0.1580 - category_output_loss: 0.0754 - color_output_loss: 0.0826 - category_output_acc: 0.9710 - color_output_acc: 0.9699 - val_loss: 7.0514 - val_category_output_loss: 6.9553 - val_color_output_loss: 0.0961 - val_category_output_acc: 0.3686 - val_color_output_acc: 0.9613\n",
            "Epoch 12/50\n",
            "1963/1963 [==============================] - 4s 2ms/step - loss: 0.1434 - category_output_loss: 0.0726 - color_output_loss: 0.0708 - category_output_acc: 0.9710 - color_output_acc: 0.9776 - val_loss: 0.4915 - val_category_output_loss: 0.4211 - val_color_output_loss: 0.0703 - val_category_output_acc: 0.8941 - val_color_output_acc: 0.9756\n",
            "Epoch 13/50\n",
            "1963/1963 [==============================] - 4s 2ms/step - loss: 0.1066 - category_output_loss: 0.0546 - color_output_loss: 0.0520 - category_output_acc: 0.9827 - color_output_acc: 0.9847 - val_loss: 0.4716 - val_category_output_loss: 0.3803 - val_color_output_loss: 0.0914 - val_category_output_acc: 0.9124 - val_color_output_acc: 0.9654\n",
            "Epoch 14/50\n",
            "1963/1963 [==============================] - 4s 2ms/step - loss: 0.1057 - category_output_loss: 0.0500 - color_output_loss: 0.0557 - category_output_acc: 0.9842 - color_output_acc: 0.9801 - val_loss: 0.4159 - val_category_output_loss: 0.3522 - val_color_output_loss: 0.0637 - val_category_output_acc: 0.9145 - val_color_output_acc: 0.9796\n",
            "Epoch 15/50\n",
            "1963/1963 [==============================] - 4s 2ms/step - loss: 0.0894 - category_output_loss: 0.0360 - color_output_loss: 0.0534 - category_output_acc: 0.9868 - color_output_acc: 0.9796 - val_loss: 0.5230 - val_category_output_loss: 0.4155 - val_color_output_loss: 0.1075 - val_category_output_acc: 0.8900 - val_color_output_acc: 0.9593\n",
            "Epoch 16/50\n",
            "1963/1963 [==============================] - 4s 2ms/step - loss: 0.0650 - category_output_loss: 0.0208 - color_output_loss: 0.0442 - category_output_acc: 0.9944 - color_output_acc: 0.9817 - val_loss: 0.7189 - val_category_output_loss: 0.5025 - val_color_output_loss: 0.2165 - val_category_output_acc: 0.8961 - val_color_output_acc: 0.9308\n",
            "Epoch 17/50\n",
            "1963/1963 [==============================] - 4s 2ms/step - loss: 0.0687 - category_output_loss: 0.0241 - color_output_loss: 0.0446 - category_output_acc: 0.9898 - color_output_acc: 0.9837 - val_loss: 0.8217 - val_category_output_loss: 0.7510 - val_color_output_loss: 0.0707 - val_category_output_acc: 0.8330 - val_color_output_acc: 0.9735\n",
            "Epoch 18/50\n",
            "1963/1963 [==============================] - 4s 2ms/step - loss: 0.0737 - category_output_loss: 0.0284 - color_output_loss: 0.0453 - category_output_acc: 0.9918 - color_output_acc: 0.9832 - val_loss: 0.3664 - val_category_output_loss: 0.3149 - val_color_output_loss: 0.0515 - val_category_output_acc: 0.9002 - val_color_output_acc: 0.9776\n",
            "Epoch 19/50\n",
            "1963/1963 [==============================] - 4s 2ms/step - loss: 0.0850 - category_output_loss: 0.0359 - color_output_loss: 0.0491 - category_output_acc: 0.9878 - color_output_acc: 0.9817 - val_loss: 0.5109 - val_category_output_loss: 0.3794 - val_color_output_loss: 0.1315 - val_category_output_acc: 0.8921 - val_color_output_acc: 0.9593\n",
            "Epoch 20/50\n",
            "1963/1963 [==============================] - 4s 2ms/step - loss: 0.0933 - category_output_loss: 0.0431 - color_output_loss: 0.0502 - category_output_acc: 0.9873 - color_output_acc: 0.9812 - val_loss: 0.5135 - val_category_output_loss: 0.4069 - val_color_output_loss: 0.1067 - val_category_output_acc: 0.9002 - val_color_output_acc: 0.9654\n",
            "Epoch 21/50\n",
            "1963/1963 [==============================] - 4s 2ms/step - loss: 0.0687 - category_output_loss: 0.0325 - color_output_loss: 0.0362 - category_output_acc: 0.9903 - color_output_acc: 0.9878 - val_loss: 0.7002 - val_category_output_loss: 0.4852 - val_color_output_loss: 0.2150 - val_category_output_acc: 0.8758 - val_color_output_acc: 0.9328\n",
            "Epoch 22/50\n",
            "1963/1963 [==============================] - 4s 2ms/step - loss: 0.0646 - category_output_loss: 0.0184 - color_output_loss: 0.0462 - category_output_acc: 0.9918 - color_output_acc: 0.9847 - val_loss: 0.4888 - val_category_output_loss: 0.4000 - val_color_output_loss: 0.0888 - val_category_output_acc: 0.8961 - val_color_output_acc: 0.9695\n",
            "Epoch 23/50\n",
            "1963/1963 [==============================] - 4s 2ms/step - loss: 0.0791 - category_output_loss: 0.0265 - color_output_loss: 0.0526 - category_output_acc: 0.9903 - color_output_acc: 0.9817 - val_loss: 0.5852 - val_category_output_loss: 0.4680 - val_color_output_loss: 0.1172 - val_category_output_acc: 0.8961 - val_color_output_acc: 0.9633\n",
            "Epoch 24/50\n",
            "1963/1963 [==============================] - 4s 2ms/step - loss: 0.0678 - category_output_loss: 0.0344 - color_output_loss: 0.0334 - category_output_acc: 0.9888 - color_output_acc: 0.9868 - val_loss: 0.5327 - val_category_output_loss: 0.4529 - val_color_output_loss: 0.0797 - val_category_output_acc: 0.8839 - val_color_output_acc: 0.9715\n",
            "Epoch 25/50\n",
            "1963/1963 [==============================] - 4s 2ms/step - loss: 0.0735 - category_output_loss: 0.0440 - color_output_loss: 0.0295 - category_output_acc: 0.9847 - color_output_acc: 0.9888 - val_loss: 0.5202 - val_category_output_loss: 0.4118 - val_color_output_loss: 0.1084 - val_category_output_acc: 0.8880 - val_color_output_acc: 0.9735\n",
            "Epoch 26/50\n",
            "1963/1963 [==============================] - 4s 2ms/step - loss: 0.0706 - category_output_loss: 0.0172 - color_output_loss: 0.0534 - category_output_acc: 0.9929 - color_output_acc: 0.9842 - val_loss: 0.5264 - val_category_output_loss: 0.4566 - val_color_output_loss: 0.0699 - val_category_output_acc: 0.8961 - val_color_output_acc: 0.9776\n",
            "Epoch 27/50\n",
            "1963/1963 [==============================] - 4s 2ms/step - loss: 0.0517 - category_output_loss: 0.0229 - color_output_loss: 0.0288 - category_output_acc: 0.9954 - color_output_acc: 0.9903 - val_loss: 0.4401 - val_category_output_loss: 0.3451 - val_color_output_loss: 0.0950 - val_category_output_acc: 0.9165 - val_color_output_acc: 0.9735\n",
            "Epoch 28/50\n",
            "1963/1963 [==============================] - 4s 2ms/step - loss: 0.0769 - category_output_loss: 0.0424 - color_output_loss: 0.0345 - category_output_acc: 0.9862 - color_output_acc: 0.9868 - val_loss: 0.5461 - val_category_output_loss: 0.4895 - val_color_output_loss: 0.0566 - val_category_output_acc: 0.8859 - val_color_output_acc: 0.9756\n",
            "Epoch 29/50\n",
            "1963/1963 [==============================] - 4s 2ms/step - loss: 0.0412 - category_output_loss: 0.0203 - color_output_loss: 0.0209 - category_output_acc: 0.9924 - color_output_acc: 0.9934 - val_loss: 0.4930 - val_category_output_loss: 0.4227 - val_color_output_loss: 0.0702 - val_category_output_acc: 0.8982 - val_color_output_acc: 0.9796\n",
            "Epoch 30/50\n",
            "1963/1963 [==============================] - 4s 2ms/step - loss: 0.0514 - category_output_loss: 0.0237 - color_output_loss: 0.0277 - category_output_acc: 0.9918 - color_output_acc: 0.9908 - val_loss: 0.5874 - val_category_output_loss: 0.5294 - val_color_output_loss: 0.0580 - val_category_output_acc: 0.8615 - val_color_output_acc: 0.9756\n",
            "Epoch 31/50\n",
            "1963/1963 [==============================] - 4s 2ms/step - loss: 0.0411 - category_output_loss: 0.0193 - color_output_loss: 0.0217 - category_output_acc: 0.9964 - color_output_acc: 0.9939 - val_loss: 0.6854 - val_category_output_loss: 0.5217 - val_color_output_loss: 0.1637 - val_category_output_acc: 0.8880 - val_color_output_acc: 0.9593\n",
            "Epoch 32/50\n",
            "1963/1963 [==============================] - 4s 2ms/step - loss: 0.0583 - category_output_loss: 0.0254 - color_output_loss: 0.0329 - category_output_acc: 0.9913 - color_output_acc: 0.9893 - val_loss: 0.6346 - val_category_output_loss: 0.5533 - val_color_output_loss: 0.0813 - val_category_output_acc: 0.8493 - val_color_output_acc: 0.9735\n",
            "Epoch 33/50\n",
            "1963/1963 [==============================] - 4s 2ms/step - loss: 0.0635 - category_output_loss: 0.0249 - color_output_loss: 0.0386 - category_output_acc: 0.9929 - color_output_acc: 0.9857 - val_loss: 0.6111 - val_category_output_loss: 0.5275 - val_color_output_loss: 0.0836 - val_category_output_acc: 0.8921 - val_color_output_acc: 0.9756\n",
            "Epoch 34/50\n",
            "1963/1963 [==============================] - 4s 2ms/step - loss: 0.0451 - category_output_loss: 0.0197 - color_output_loss: 0.0255 - category_output_acc: 0.9954 - color_output_acc: 0.9908 - val_loss: 0.6163 - val_category_output_loss: 0.5559 - val_color_output_loss: 0.0604 - val_category_output_acc: 0.8819 - val_color_output_acc: 0.9756\n",
            "Epoch 35/50\n",
            "1963/1963 [==============================] - 4s 2ms/step - loss: 0.0534 - category_output_loss: 0.0205 - color_output_loss: 0.0329 - category_output_acc: 0.9939 - color_output_acc: 0.9883 - val_loss: 0.5206 - val_category_output_loss: 0.4605 - val_color_output_loss: 0.0601 - val_category_output_acc: 0.8921 - val_color_output_acc: 0.9735\n",
            "Epoch 36/50\n",
            "1963/1963 [==============================] - 4s 2ms/step - loss: 0.0535 - category_output_loss: 0.0223 - color_output_loss: 0.0312 - category_output_acc: 0.9929 - color_output_acc: 0.9898 - val_loss: 0.9308 - val_category_output_loss: 0.5315 - val_color_output_loss: 0.3992 - val_category_output_acc: 0.8798 - val_color_output_acc: 0.8615\n",
            "Epoch 37/50\n",
            "1963/1963 [==============================] - 4s 2ms/step - loss: 0.0590 - category_output_loss: 0.0224 - color_output_loss: 0.0366 - category_output_acc: 0.9934 - color_output_acc: 0.9888 - val_loss: 0.4863 - val_category_output_loss: 0.3890 - val_color_output_loss: 0.0973 - val_category_output_acc: 0.8982 - val_color_output_acc: 0.9654\n",
            "Epoch 38/50\n",
            "1963/1963 [==============================] - 4s 2ms/step - loss: 0.0351 - category_output_loss: 0.0156 - color_output_loss: 0.0194 - category_output_acc: 0.9949 - color_output_acc: 0.9939 - val_loss: 0.5231 - val_category_output_loss: 0.4481 - val_color_output_loss: 0.0749 - val_category_output_acc: 0.8839 - val_color_output_acc: 0.9715\n",
            "Epoch 39/50\n",
            "1963/1963 [==============================] - 4s 2ms/step - loss: 0.0320 - category_output_loss: 0.0119 - color_output_loss: 0.0202 - category_output_acc: 0.9964 - color_output_acc: 0.9929 - val_loss: 0.4879 - val_category_output_loss: 0.4312 - val_color_output_loss: 0.0567 - val_category_output_acc: 0.8941 - val_color_output_acc: 0.9796\n",
            "Epoch 40/50\n",
            "1963/1963 [==============================] - 4s 2ms/step - loss: 0.0358 - category_output_loss: 0.0101 - color_output_loss: 0.0257 - category_output_acc: 0.9985 - color_output_acc: 0.9913 - val_loss: 0.5183 - val_category_output_loss: 0.4308 - val_color_output_loss: 0.0875 - val_category_output_acc: 0.9145 - val_color_output_acc: 0.9654\n",
            "Epoch 41/50\n",
            "1963/1963 [==============================] - 4s 2ms/step - loss: 0.0302 - category_output_loss: 0.0110 - color_output_loss: 0.0192 - category_output_acc: 0.9975 - color_output_acc: 0.9934 - val_loss: 0.5763 - val_category_output_loss: 0.4542 - val_color_output_loss: 0.1222 - val_category_output_acc: 0.9104 - val_color_output_acc: 0.9613\n",
            "Epoch 42/50\n",
            "1963/1963 [==============================] - 4s 2ms/step - loss: 0.0613 - category_output_loss: 0.0216 - color_output_loss: 0.0397 - category_output_acc: 0.9934 - color_output_acc: 0.9868 - val_loss: 0.8422 - val_category_output_loss: 0.7037 - val_color_output_loss: 0.1385 - val_category_output_acc: 0.8900 - val_color_output_acc: 0.9633\n",
            "Epoch 43/50\n",
            "1963/1963 [==============================] - 4s 2ms/step - loss: 0.0589 - category_output_loss: 0.0233 - color_output_loss: 0.0357 - category_output_acc: 0.9939 - color_output_acc: 0.9862 - val_loss: 0.5874 - val_category_output_loss: 0.4939 - val_color_output_loss: 0.0935 - val_category_output_acc: 0.9124 - val_color_output_acc: 0.9715\n",
            "Epoch 44/50\n",
            "1963/1963 [==============================] - 4s 2ms/step - loss: 0.0511 - category_output_loss: 0.0153 - color_output_loss: 0.0358 - category_output_acc: 0.9954 - color_output_acc: 0.9888 - val_loss: 0.6388 - val_category_output_loss: 0.5091 - val_color_output_loss: 0.1297 - val_category_output_acc: 0.8941 - val_color_output_acc: 0.9695\n",
            "Epoch 45/50\n",
            "1963/1963 [==============================] - 4s 2ms/step - loss: 0.0384 - category_output_loss: 0.0178 - color_output_loss: 0.0206 - category_output_acc: 0.9944 - color_output_acc: 0.9934 - val_loss: 0.5282 - val_category_output_loss: 0.4404 - val_color_output_loss: 0.0878 - val_category_output_acc: 0.9063 - val_color_output_acc: 0.9776\n",
            "Epoch 46/50\n",
            "1963/1963 [==============================] - 4s 2ms/step - loss: 0.0357 - category_output_loss: 0.0140 - color_output_loss: 0.0217 - category_output_acc: 0.9969 - color_output_acc: 0.9944 - val_loss: 0.4834 - val_category_output_loss: 0.3952 - val_color_output_loss: 0.0882 - val_category_output_acc: 0.9063 - val_color_output_acc: 0.9735\n",
            "Epoch 47/50\n",
            "1963/1963 [==============================] - 4s 2ms/step - loss: 0.0378 - category_output_loss: 0.0167 - color_output_loss: 0.0210 - category_output_acc: 0.9949 - color_output_acc: 0.9924 - val_loss: 0.5286 - val_category_output_loss: 0.3614 - val_color_output_loss: 0.1673 - val_category_output_acc: 0.9185 - val_color_output_acc: 0.9511\n",
            "Epoch 48/50\n",
            "1963/1963 [==============================] - 4s 2ms/step - loss: 0.0550 - category_output_loss: 0.0309 - color_output_loss: 0.0240 - category_output_acc: 0.9883 - color_output_acc: 0.9924 - val_loss: 0.8071 - val_category_output_loss: 0.6145 - val_color_output_loss: 0.1926 - val_category_output_acc: 0.8513 - val_color_output_acc: 0.9430\n",
            "Epoch 49/50\n",
            "1963/1963 [==============================] - 4s 2ms/step - loss: 0.0819 - category_output_loss: 0.0433 - color_output_loss: 0.0386 - category_output_acc: 0.9857 - color_output_acc: 0.9883 - val_loss: 2.7382 - val_category_output_loss: 2.6217 - val_color_output_loss: 0.1165 - val_category_output_acc: 0.6864 - val_color_output_acc: 0.9654\n",
            "Epoch 50/50\n",
            "1963/1963 [==============================] - 4s 2ms/step - loss: 0.0565 - category_output_loss: 0.0367 - color_output_loss: 0.0198 - category_output_acc: 0.9862 - color_output_acc: 0.9939 - val_loss: 0.6142 - val_category_output_loss: 0.5516 - val_color_output_loss: 0.0626 - val_category_output_acc: 0.8798 - val_color_output_acc: 0.9756\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMi5DDg7c4hp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot for losses\n",
        "\n",
        "loss_names = [\"loss\", \"category_output_loss\", \"color_output_loss\"]\n",
        "plt.style.use(\"ggplot\")\n",
        "\n",
        "(fig, ax) = plt.subplots(3, 1, figsize=(13, 13))\n",
        "\n",
        "# loop over the loss names\n",
        "for (i, l) in enumerate(loss_names):\n",
        "  title = \"Loss for {}\".format(l) if l != \"loss\" else \"Total loss\"\n",
        "  ax[i].set_title(title)\n",
        "  ax[i].set_xlabel(\"Epoch #\")\n",
        "  ax[i].set_ylabel(\"loss\")\n",
        "  ax[i].plot(np.arange(0, epochs), H.history[l], label=l)\n",
        "  ax[i].plot(np.arange(0, epochs), H.history[\"val_\"+ l], label=\"val_\"+l)\n",
        "  ax[i].legend()\n",
        "\n",
        "# save the losses\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"{}_losses.png\".format('multi'))\n",
        "plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgE0YAzbelNd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot for accuracy\n",
        "\n",
        "acc_names = [\"category_output_acc\", 'color_output_acc']\n",
        "plt.style.use(\"ggplot\")\n",
        "(fig, ax) = plt.subplots(2, 1, figsize=(8, 8))\n",
        "\n",
        "for (i, l) in enumerate(acc_names):\n",
        "  ax[i].set_title(\"Accuracy for {}\".format(l))\n",
        "  ax[i].set_xlabel(\"Epoch #\")\n",
        "  ax[i].set_ylabel(\"Accuracy\")\n",
        "  ax[i].plot(np.arange(0, epochs), H.history[l], label=l)\n",
        "  ax[i].plot(np.arange(0, epochs), H.history[\"val_\"+ l], label=\"val_\"+l)\n",
        "  ax[i].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"{}_acc.png\".format('multi'))\n",
        "plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHTtAE2ZiR2g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}